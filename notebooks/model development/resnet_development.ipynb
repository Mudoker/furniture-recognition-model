{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:20:33.851408: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 16:20:33.851452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 16:20:33.852325: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-16 16:20:33.857816: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 16:20:34.656817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:20:36.538405: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:36.577253: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:36.577526: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# Build a Resnet model from scratch\n",
    "import os  # OS related functions\n",
    "import numpy as np  # Numerical functions\n",
    "import pandas as pd  # Data manipulation\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import seaborn as sns  # Plotting\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential  # Pipeline\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau  # Callbacks\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    ")  # Image data generator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Add\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import classification_report  # Metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Class weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\n",
    "    \"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196626 entries, 0 to 196625\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   Path      196626 non-null  object \n",
      " 1   Category  196626 non-null  object \n",
      " 2   Style     196626 non-null  object \n",
      " 3   Width     196626 non-null  int64  \n",
      " 4   Height    196626 non-null  int64  \n",
      " 5   MinValue  196626 non-null  int64  \n",
      " 6   MaxValue  196626 non-null  int64  \n",
      " 7   StdDev    196626 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 12.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>MinValue</th>\n",
       "      <th>MaxValue</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/d...</td>\n",
       "      <td>dressers</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>78.264032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>56.407194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/d...</td>\n",
       "      <td>dressers</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>69.652896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>84.765229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>56.764965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  Category  Style  Width  \\\n",
       "0  ../../data/raw/Furniture_Data/Furniture_Data/d...  dressers  Asian    256   \n",
       "1  ../../data/raw/Furniture_Data/Furniture_Data/l...     lamps  Asian    256   \n",
       "2  ../../data/raw/Furniture_Data/Furniture_Data/d...  dressers  Asian    256   \n",
       "3  ../../data/raw/Furniture_Data/Furniture_Data/l...     lamps  Asian    256   \n",
       "4  ../../data/raw/Furniture_Data/Furniture_Data/l...     lamps  Asian    256   \n",
       "\n",
       "   Height  MinValue  MaxValue     StdDev  \n",
       "0     256         0       255  78.264032  \n",
       "1     256         0       255  56.407194  \n",
       "2     256         0       255  69.652896  \n",
       "3     256         5       255  84.765229  \n",
       "4     256         2       255  56.764965  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "num_classes = 17\n",
    "\n",
    "df_train = pd.read_csv(\"../../data/processed/train.csv\")  # Load train data\n",
    "df_test = pd.read_csv(\"../../data/test/test.csv\")  # Load test data\n",
    "\n",
    "# convert \\ to / in path\n",
    "df_train[\"Path\"] = df_train[\"Path\"].str.replace(\"\\\\\", \"/\")\n",
    "df_test[\"Path\"] = df_test[\"Path\"].str.replace(\"\\\\\", \"/\")\n",
    "\n",
    "df_train.info()  # Display data information\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 196626 validated image filenames belonging to 17 classes.\n",
      "Found 11475 validated image filenames belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = df_train[\"Style\"].nunique()  # Number of classes\n",
    "\n",
    "# Image data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Separate the test dataset for validation\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size = 32  # Number of samples per gradient update\n",
    "num_classes = df_train[\"Style\"].nunique()  # Number of classes\n",
    "\n",
    "# Image data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Common arguments\n",
    "common_args = {\n",
    "    \"x_col\": \"Path\",  # Path to image\n",
    "    \"y_col\": \"Style\",  # Target column\n",
    "    \"batch_size\": batch_size,  # Batch size\n",
    "    \"class_mode\": \"categorical\",  # Multi-class classification\n",
    "    \"target_size\": (image_size, image_size),  # Specify the target image size\n",
    "}\n",
    "\n",
    "# Create generator for training data\n",
    "train_dataset = datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,  # Training data\n",
    "    shuffle=True,  # Shuffle the data\n",
    "    **common_args  # Common arguments\n",
    ")\n",
    "\n",
    "# Create generator for testing data\n",
    "val_dataset = datagen.flow_from_dataframe(\n",
    "    dataframe=df_val,  # Testing data\n",
    "    shuffle=False,  # Do not shuffle the data\n",
    "    **common_args  # Common arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mappings for different categories:\n",
      "0 : Asian\n",
      "1 : Beach\n",
      "2 : Contemporary\n",
      "3 : Craftsman\n",
      "4 : Eclectic\n",
      "5 : Farmhouse\n",
      "6 : Industrial\n",
      "7 : Mediterranean\n",
      "8 : Midcentury\n",
      "9 : Modern\n",
      "10 : Rustic\n",
      "11 : Scandinavian\n",
      "12 : Southwestern\n",
      "13 : Traditional\n",
      "14 : Transitional\n",
      "15 : Tropical\n",
      "16 : Victorian\n"
     ]
    }
   ],
   "source": [
    "labels = {value: key for key, value in train_dataset.class_indices.items()}\n",
    "\n",
    "print(\"Label Mappings for different categories:\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link for the overview of the building block of Resnet: https://pytorch.org/hub/pytorch_vision_resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Resnet34 from scratch\n",
    "class ConvLayer(models.Model):\n",
    "    def __init__(self, filters, kernel_size, strides=(1, 1)):\n",
    "        super(ConvLayer, self).__init__(name=\"conv_layer\")\n",
    "\n",
    "        self.conv = layers.Conv2D(\n",
    "            filters, kernel_size, strides=strides, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x, training=training)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResnetBlock(models.Model):\n",
    "    def __init__(self, filters, strides=(1, 1)):\n",
    "        super(ResnetBlock, self).__init__(name=\"resnet_block\")\n",
    "\n",
    "        self.conv1 = ConvLayer(filters, (3, 3), strides=strides)\n",
    "        self.conv2 = ConvLayer(filters, (3, 3))\n",
    "        self.activation = layers.Activation(\"relu\")\n",
    "\n",
    "        if strides != (1, 1):\n",
    "            self.conv3 = ConvLayer(filters, (1, 1), strides=strides)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs, training=training)\n",
    "        x = self.conv2(x, training=training)\n",
    "\n",
    "        if hasattr(self, \"conv3\"):\n",
    "            x_add = self.conv3(inputs, training=training)\n",
    "            x_add = Add()([x, x_add])\n",
    "        else:\n",
    "            x_add = Add()([x, inputs])\n",
    "\n",
    "        return self.activation(x_add)\n",
    "\n",
    "\n",
    "class Resnet34(models.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet34, self).__init__(name=\"resnet34\")\n",
    "\n",
    "        self.conv1 = ConvLayer(64, (7, 7), strides=(2, 2))\n",
    "        self.maxpool = layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")\n",
    "\n",
    "        # Residual blocks\n",
    "        self.conv2_1 = ResnetBlock(64)\n",
    "        self.conv2_2 = ResnetBlock(64)\n",
    "        self.conv2_3 = ResnetBlock(64)\n",
    "\n",
    "        self.conv3_1 = ResnetBlock(128, strides=(2, 2))\n",
    "        self.conv3_2 = ResnetBlock(128)\n",
    "        self.conv3_3 = ResnetBlock(128)\n",
    "        self.conv3_4 = ResnetBlock(128)\n",
    "\n",
    "        self.conv4_1 = ResnetBlock(256, strides=(2, 2))\n",
    "        self.conv4_2 = ResnetBlock(256)\n",
    "        self.conv4_3 = ResnetBlock(256)\n",
    "        self.conv4_4 = ResnetBlock(256)\n",
    "        self.conv4_5 = ResnetBlock(256)\n",
    "        self.conv4_6 = ResnetBlock(256)\n",
    "\n",
    "        self.conv5_1 = ResnetBlock(512, strides=(2, 2))\n",
    "        self.conv5_2 = ResnetBlock(512)\n",
    "        self.conv5_3 = ResnetBlock(512)\n",
    "\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv2_1(x, training=True)\n",
    "        x = self.conv2_2(x, training=True)\n",
    "        x = self.conv2_3(x, training=True)\n",
    "\n",
    "        x = self.conv3_1(x, training=True)\n",
    "        x = self.conv3_2(x, training=True)\n",
    "        x = self.conv3_3(x, training=True)\n",
    "        x = self.conv3_4(x, training=True)\n",
    "\n",
    "        x = self.conv4_1(x, training=True)\n",
    "        x = self.conv4_2(x, training=True)\n",
    "        x = self.conv4_3(x, training=True)\n",
    "        x = self.conv4_4(x, training=True)\n",
    "        x = self.conv4_5(x, training=True)\n",
    "        x = self.conv4_6(x, training=True)\n",
    "\n",
    "        x = self.conv5_1(x, training=True)\n",
    "        x = self.conv5_2(x, training=True)\n",
    "        x = self.conv5_3(x, training=True)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:20:37.772135: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.772461: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.772653: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.881836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.882222: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.882236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-16 16:20:37.882495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-16 16:20:37.882522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-16 16:20:38.169640: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-16 16:20:38.280002: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-16 16:20:38.549254: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_layer (ConvLayer)      multiple                  9728      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  231296    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_layer (ConvLayer)      multiple                  9728      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  231296    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  296192    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  921344    \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  1182208   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  1182208   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  1182208   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  1182208   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  1182208   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  3677696   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  4723712   \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  4723712   \n",
      "                                                                 \n",
      " global_average_pooling2d (  multiple                  0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21318929 (81.33 MB)\n",
      "Trainable params: 21301905 (81.26 MB)\n",
      "Non-trainable params: 17024 (66.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = Resnet34(num_classes)\n",
    "resnet_34(tf.zeros((1, 256, 256, 3)), training=False)\n",
    "\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Monitor validation loss\n",
    "    patience=5,  # Stop training if no improvement for 5 epochs\n",
    "    restore_best_weights=True,  # Restore the best weights when stopping\n",
    "    min_delta=0.001,  # Minimum change to qualify as an improvement\n",
    "    verbose=1,  # Print messages\n",
    ")\n",
    "\n",
    "# Reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",  # Monitor validation loss\n",
    "    patience=5,  # Reduce learning rate if no improvement for 3 epochs\n",
    "    factor=0.5,  # Factor by 0.5\n",
    "    min_lr=0.00001,  # Minimum learning rate\n",
    "    verbose=1,  # Print messages\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(df_train[\"Style\"]),\n",
    "    y=df_train[\"Style\"],\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Convert class weights to dictionary\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Compile the model\n",
    "resnet_34.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")  # Compile model\n",
    "\n",
    "# CSV logger\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "    \"./cache_cnn/training.csv\", separator=\",\", append=False\n",
    ")  # CSV logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "6145/6145 [==============================] - 2258s 367ms/step - loss: 0.9255 - accuracy: 0.4658 - val_loss: 1.9601 - val_accuracy: 0.3800 - lr: 1.0000e-04\n",
      "Epoch 2/32\n",
      "6145/6145 [==============================] - 2257s 367ms/step - loss: 0.8219 - accuracy: 0.4934 - val_loss: 1.9940 - val_accuracy: 0.3848 - lr: 1.0000e-04\n",
      "Epoch 3/32\n",
      "6145/6145 [==============================] - 2257s 367ms/step - loss: 0.7412 - accuracy: 0.5206 - val_loss: 2.0404 - val_accuracy: 0.3866 - lr: 1.0000e-04\n",
      "Epoch 4/32\n",
      "6145/6145 [==============================] - 2258s 367ms/step - loss: 0.6597 - accuracy: 0.5499 - val_loss: 2.0658 - val_accuracy: 0.3956 - lr: 1.0000e-04\n",
      "Epoch 5/32\n",
      "6145/6145 [==============================] - 2258s 367ms/step - loss: 0.6080 - accuracy: 0.5720 - val_loss: 2.1224 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 6/32\n",
      "6145/6145 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.5948Restoring model weights from the end of the best epoch: 1.\n",
      "6145/6145 [==============================] - 2257s 367ms/step - loss: 0.5574 - accuracy: 0.5948 - val_loss: 2.1005 - val_accuracy: 0.4037 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f005410bf50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_34.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=32,\n",
    "    callbacks=[early_stopping, reduce_lr, csv_logger],\n",
    "    class_weight=class_weight_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mudoker/anaconda3/envs/py31/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresnet_34\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./cache_resnet/r34.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to ./cache_resnet/r34.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save the weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py31/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py31/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:152\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m     save_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile))\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m saving_utils\u001b[38;5;241m.\u001b[39mis_hdf5_filepath(filepath)\n\u001b[1;32m    147\u001b[0m ):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# TODO(b/130258301): add utility method for detecting model type.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    150\u001b[0m         model, sequential\u001b[38;5;241m.\u001b[39mSequential\n\u001b[1;32m    151\u001b[0m     ):\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclassed models, because such models are defined via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody of a Python method, which isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt safely serializable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider saving to the Tensorflow SavedModel format (by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m     hdf5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    161\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "resnet_34.save(\"./cache_resnet/r34.h5\")  # Save model\n",
    "print(f\"Model saved to ./cache_resnet/r34.h5\")\n",
    "\n",
    "# Save the weights\n",
    "resnet_34.save_weights(\"./cache_resnet/weights_34.h5\")  # Save weights\n",
    "print(f\"Weights saved to ./cache_resnet/weights_34.h5\")\n",
    "\n",
    "# Save model\n",
    "resnet_34.save(\"./cache_resnet/r34\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

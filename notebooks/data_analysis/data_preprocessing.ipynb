{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Data Preprocessing**\n",
    "\n",
    "<center>────────────────────────────</center>\n",
    "&nbsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "In this notebook, we will apply common data preprocessing techniques to the dataset, building on the analysis conducted during the *exploratory data analysis* (EDA) steps. Data preprocessing is essential in the machine learning pipeline as it helps clean, transform, and prepare the data for the model.\n",
    "\n",
    "The following preprocessing steps will be implemented:\n",
    "\n",
    "1. **Image Labeling**: Labels associated with each image will be extracted from the filenames and stored in a designated column within a Pandas DataFrame.\n",
    "   \n",
    "2. **Image Resizing**: All images will be resized to a uniform dimension, ensuring consistency across the dataset.\n",
    "\n",
    "3. **Data Augmentation**: The images are augmented to increase the size of the dataset and improve the model's generalization.\n",
    "   \n",
    "4. **Pixel Normalization**: The pixel values are normalized to a range of [`0`, `1`] to ensure that the model can learn effectively.\n",
    "   \n",
    "5. **Train-Test Split**: The dataset will be divided into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate its performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        @|\\@@\n",
      "       -  @@@@                                                            LEON 1.0.0\n",
      "      /7   @@@@                                         This is Leon, the friendly lion. He is here to help you\n",
      "     /    @@@@@@                                     Leon is tailored to manipulate images, data and visualizations\n",
      "     \\-' @@@@@@@@`-_______________                                      Made by: Team X\n",
      "      -@@@@@@@@@             /    \\                                     Version: 1.0.3\n",
      " _______/    /_       ______/      |__________-\n",
      "/,__________/  `-.___/,_____________----------_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd  # Data manipulation\n",
    "import sys  # System specific parameters and functions\n",
    "import importlib  # Importing modules\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reload modules\n",
    "sys.path.append(\"../../\")  # Root directory\n",
    "modules_to_reload = [\"scripts.leon\", \"scripts.styler\"]\n",
    "\n",
    "# Reload modules if they have been modified\n",
    "missing_modules = []\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        missing_modules.append(module_name)\n",
    "\n",
    "# Recache missing modules\n",
    "if missing_modules:\n",
    "    print(f\"Modules {missing_modules} not found. /nRecaching...\")\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.leon import Leon  # Leon class\n",
    "from scripts.styler import Styler  # Styler class\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "# Initialize objects\n",
    "leon = Leon()\n",
    "styler = Styler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory path\n",
    "raw_dir = \"../../data/raw/Furniture_Data/Furniture_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we conclude from the *exploratory data analysis* (EDA), there is a mismatch between the file format of `jpgD` and the other `jpg` files. Hence, to ensure that the data is consistent, we will change the file format of `jpgD` to `jpg`. Based on testing and observation, simply changing the file format from `jpgD` to `jpg` does not affect the image quality or integrity.\n",
    "\n",
    "This adjustment will help maintain consistency across the dataset and prevent any potential issues during the preprocessing and modeling stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huuqu\\Academic\\RMIT\\Machine Learning\\Group Assignment\\data\\raw\\Furniture_Data\\Furniture_Data\\dressers\\Farmhouse\\30826farmhouse-coffee-tables.jpgD\n",
      "File not found or has been renamed already.\n"
     ]
    }
   ],
   "source": [
    "# Original file path\n",
    "jpgd_path = \"../../data/raw/Furniture_Data/Furniture_Data/dressers/Farmhouse/30826farmhouse-coffee-tables.jpgD\"\n",
    "\n",
    "# Get the absolute path\n",
    "jpgd_path = os.path.abspath(jpgd_path)\n",
    "\n",
    "print (jpgd_path)\n",
    "# Check if the file exists\n",
    "if os.path.exists(jpgd_path):\n",
    "    # Get the directory and file name\n",
    "    directory, filename = os.path.split(jpgd_path)\n",
    "\n",
    "    # Remove the extra characters after \".jpg\" in the filename\n",
    "    new_filename = filename.split(\".jpg\")[0] + \".jpg\"\n",
    "\n",
    "    # Create the new file path\n",
    "    new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "    # Rename the file\n",
    "    os.rename(jpgd_path, new_path)\n",
    "\n",
    "    print(f\"File renamed from '{jpgd_path}' to '{new_path}'\")\n",
    "else:\n",
    "    print(\"File not found or has been renamed already.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Labeling and Training-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will process the image filenames to extract labels. These labels will be stored in a new column within our Pandas DataFrame. This process will enable us to conveniently access and manage the images using Pandas' built-in functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = leon.load_data_frame(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81935 entries, 0 to 81934\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Path    81935 non-null  object\n",
      " 1   Class   81935 non-null  object\n",
      " 2   Style   81935 non-null  object\n",
      " 3   Width   81935 non-null  int64 \n",
      " 4   Height  81935 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path Class  Style  Width  \\\n",
       "0  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...  beds  Asian    256   \n",
       "1  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...  beds  Asian    256   \n",
       "2  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...  beds  Asian    256   \n",
       "3  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...  beds  Asian    256   \n",
       "4  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\b...  beds  Asian    256   \n",
       "\n",
       "   Height  \n",
       "0     256  \n",
       "1     256  \n",
       "2     256  \n",
       "3     256  \n",
       "4     256  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65546 entries, 35858 to 60909\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Path      65546 non-null  object\n",
      " 1   Category  65546 non-null  object\n",
      " 2   Style     65546 non-null  object\n",
      " 3   Width     65546 non-null  object\n",
      " 4   Height    65546 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 3.0+ MB\n",
      "\n",
      "Count of each style in the train set:\n",
      "Category\n",
      "lamps       20915\n",
      "chairs      16681\n",
      "tables      13361\n",
      "dressers     6152\n",
      "beds         5235\n",
      "sofas        3202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupby(\"Style\")\n",
    "\n",
    "# Initialize empty DataFrames for train and test sets\n",
    "df_train = pd.DataFrame(columns=df.columns)\n",
    "df_test = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Split each group and concatenate train and test sets\n",
    "for _, group in grouped_df:\n",
    "    train_group, test_group = train_test_split(group, test_size=0.2, random_state=42)\n",
    "    df_train = pd.concat([df_train, train_group])\n",
    "    df_test = pd.concat([df_test, test_group])\n",
    "\n",
    "# Write test set to CSV\n",
    "df_test.to_csv(\"../../data/test/test.csv\", index=False)\n",
    "\n",
    "# Display info of the training set\n",
    "df_train.info()\n",
    "\n",
    "# Print count of each style in the train set\n",
    "style_counts = df_train[\"Category\"].value_counts()\n",
    "print(\"\\nCount of each style in the train set:\")\n",
    "print(style_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will resize all images to a uniform dimension. This step is crucial as it ensures that all images have the same size, which is a requirement for most machine learning models.\n",
    "\n",
    "While there's no single \"**best**\" image size for deep learning applications, we will resize our images to `256x256` pixels. This choice balances the need to capture sufficient detail in the images with computational efficiency. Additionally, research by O. Rukundo (Lund University) suggests that `256x256` pixels is a common and effective size for processing medical images, particularly **LGE-MRI** images. \n",
    "\n",
    "Although our dataset is not related to medical imaging, we can leverage this insight of its reliability to guide our decision.\n",
    "\n",
    "[Link to Research](https://www.mdpi.com/2079-9292/12/4/985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mleon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\Academic\\RMIT\\Machine Learning\\Group Assignment\\notebooks\\data_analysis\\../..\\scripts\\leon.py:325\u001b[0m, in \u001b[0;36mLeon.resize_image\u001b[1;34m(self, path, width, height)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03mResizes the image to the specified width and height.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;124;03m    height (int): The height of the resized image.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Open the image file\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    326\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;66;03m# Resize the image\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img_path in df_train[\"Path\"]:\n",
    "    leon.resize_image(img_path, 256, 256)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, data augmentation is a well-established technique employed to artificially expand the size of a dataset. This is achieved by applying various transformations to the existing data points. Data augmentation proves particularly valuable when dealing with limited datasets, as it mitigates the risk of overfitting and enhances the model's ability to generalize to unseen data.\n",
    "\n",
    "While our image dataset may not be severely restricted in size, data augmentation can still provide significant benefits. We will incorporate the following transformations to augment our dataset:\n",
    "\n",
    "1. **Random Rotation**: Images will be rotated by a random angle within a predefined range.\n",
    "2. **Vertical Flip**: Images will be flipped along the vertical axis.\n",
    "3. **Random Contrast Adjustment**: The contrast of each image will be adjusted by a random factor.\n",
    "\n",
    "These aforementioned transformations are commonly utilized in image augmentation and demonstrably assist the model in learning robust features from the data [1]. It is important to note that with a dataset exceeding `80,000` images, employing an excessive number of augmentation techniques would result in a computationally expensive dataset to process. Therefore, a selection of the top `3` prevalent and effective transformations has been chosen.\n",
    "\n",
    "Following this augmentation step, we will possess a dataset that is approximately **three times** larger than the original dataset. This expanded dataset will equip the model with a richer learning experience and improved generalizability.\n",
    "\n",
    "[1] [Image Data Augmentation for Computer Vision](https://viso.ai/computer-vision/image-data-augmentation-for-computer-vision/#:~:text=Popular%20Types%20and%20Methods%20of%20Data%20Augmentation,-Early%20experiments%20showing&text=Geometric%20transformations%3A%20Augmenting%20image%20data,%2Fdown%2C%20or%20noise%20injection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_output_folders_and_files(df_train):\n",
    "    processed_directories = set()\n",
    "\n",
    "    for img_path in df_train[\"Path\"]:\n",
    "        # Extract directory name\n",
    "        directory = os.path.dirname(img_path)\n",
    "\n",
    "        # Check if directory has already been processed\n",
    "        if directory in processed_directories:\n",
    "            continue\n",
    "\n",
    "        # Add directory to the set of processed directories\n",
    "        processed_directories.add(directory)\n",
    "\n",
    "        # Remove files starting with \"augmented_\" if they exist\n",
    "        files_in_directory = os.listdir(directory)\n",
    "        for file_name in files_in_directory:\n",
    "            if file_name.startswith(\"aug_\"):\n",
    "                file_path = os.path.join(directory, file_name)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Removed file: {file_path}\")\n",
    "                except OSError as e:\n",
    "                    print(f\"Error removing file: {file_path}, {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed file: ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\lamps\\Asian\\aug_19274asian-table-lamps.jpg_0.jpg\n",
      "Removed file: ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\tables\\Asian\\aug_18358asian-plant-stands-and-telephone-tables.jpg_0.jpg\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Augmenting image: ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\lamps\\Asian\\19274asian-table-lamps.jpg │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "  - Saved augmented image: aug_19274asian-table-lamps.jpg_0.jpg\n",
      "  - Saved augmented image: aug_19274asian-table-lamps.jpg_1.jpg\n",
      "  - Saved augmented image: aug_19274asian-table-lamps.jpg_2.jpg\n",
      "╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Augmenting image: ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\tables\\Asian\\18358asian-plant-stands-and-telephone-tables.jpg │\n",
      "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "  - Saved augmented image: aug_18358asian-plant-stands-and-telephone-tables.jpg_0.jpg\n",
      "  - Saved augmented image: aug_18358asian-plant-stands-and-telephone-tables.jpg_1.jpg\n",
      "  - Saved augmented image: aug_18358asian-plant-stands-and-telephone-tables.jpg_2.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...</td>\n",
       "      <td>tables</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...</td>\n",
       "      <td>tables</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...</td>\n",
       "      <td>tables</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\c...</td>\n",
       "      <td>chairs</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path Category  Style Width  \\\n",
       "0  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\l...    lamps  Asian   256   \n",
       "1  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...   tables  Asian   256   \n",
       "2  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...   tables  Asian   256   \n",
       "3  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\t...   tables  Asian   256   \n",
       "4  ..\\..\\data\\raw\\Furniture_Data\\Furniture_Data\\c...   chairs  Asian   256   \n",
       "\n",
       "  Height  \n",
       "0    256  \n",
       "1    256  \n",
       "2    256  \n",
       "3    256  \n",
       "4    256  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep track of processed directories\n",
    "processed_directories = set()\n",
    "\n",
    "# Remove previous output folders and files\n",
    "remove_output_folders_and_files(df_train)\n",
    "\n",
    "count = 0\n",
    "for img_path in df_train[\"Path\"]:\n",
    "    if count == 2:\n",
    "        break\n",
    "    # Extract directory name\n",
    "    directory = os.path.dirname(img_path)\n",
    "\n",
    "    # Augment images in the directory\n",
    "    df_train = leon.augment_image(\n",
    "        image_path=img_path, output_dir=directory, df_train=df_train\n",
    "    )\n",
    "\n",
    "    count += 1\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "df_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

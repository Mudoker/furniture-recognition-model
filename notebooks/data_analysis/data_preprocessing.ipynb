{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Data Preprocessing**\n",
    "\n",
    "<center>────────────────────────────</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "Due to the **time-consuming nature** of processing this entire file, it is **highly not recommended** to re-run it in its entirety. However, **specific sections** of the file can be executed to verify the output of the **pre-processing steps**.\n",
    "\n",
    "The **pre-processed data** required for subsequent stages of the project is already available as a CSV dataframe within the **data/processed** folder. This eliminates the need to re-run the entire **pre-processing script** unless **absolutely necessary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "In this notebook, we will apply common data preprocessing techniques to the dataset, building on the analysis conducted during the *exploratory data analysis* (EDA) steps. Data preprocessing is essential in the machine learning pipeline as it helps clean, transform, and prepare the data for the model.\n",
    "\n",
    "The following preprocessing steps will be implemented:\n",
    "\n",
    "1. **Image Labeling**: Labels associated with each image will be extracted from the filenames and stored in a designated column within a Pandas DataFrame.\n",
    "\n",
    "2. **Train-Test Split**: The dataset will be divided into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate its performance on unseen data.\n",
    "\n",
    "3. **Image Resizing**: All images will be resized to a uniform dimension, ensuring consistency across the dataset.\n",
    "\n",
    "4. **Data Augmentation**: The images are augmented to increase the size of the dataset and improve the model's generalization.\n",
    "   \n",
    "5. **Pixel Normalization**: The pixel values are normalized to a range of [`0`, `1`] to ensure that the model can learn effectively.\n",
    "   \n",
    "While the detection and handling of transparent images can, in some cases, be advantageous. This is because it can help to mitigate model errors, such as PNG image formats with transparent backgrounds. This would ultimately lead to improved data quality and, consequently, enhanced model performance. However, based on the exploratory data analysis (EDA) conducted, it is evident that the dataset does not contain any transparent images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> os imported\n",
      ">>> sys imported\n",
      ">>> importlib imported\n",
      ">>> inspect imported\n",
      ">>> pandas imported as pd\n",
      ">>> numpy imported as np\n",
      ">>> matplotlib.pyplot imported as plt\n",
      ">>> seaborn imported as sns\n",
      ">>> tabulate imported\n",
      ">>> Error importing scripts.leon: No module named 'keras'\n",
      ">>> scripts.constants imported as const\n",
      ">>> scripts.styler imported as styler\n"
     ]
    }
   ],
   "source": [
    "# Base configuration for all scripts\n",
    "import sys\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split  # Split for train and test\n",
    "import warnings\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"scripts.leon\",\n",
    "    \"scripts.styler\",\n",
    "    \"scripts.utils\",\n",
    "    \"scripts.constants\",\n",
    "]\n",
    "[importlib.reload(sys.modules[m]) for m in modules_to_reload if m in sys.modules]\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.utils import Utils\n",
    "\n",
    "# Ignore future warnings as they are not applicable at the moment\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "Utils.import_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base configuration loaded successfully!\n",
      "Raw data directory:  ../../data/raw/Furniture_Data/Furniture_Data\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory path\n",
    "BASE_PATH = const.COLAB_PATH if const.IS_COLAB else const.LOCAL_PATH\n",
    "RAW_DIR = f\"{BASE_PATH}/{const.RAW_DATA_DIR}\"\n",
    "\n",
    "print (\"Base configuration loaded successfully!\")\n",
    "print (\"Raw data directory: \", RAW_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid Image Handling\n",
    "Exploratory data analysis (**EDA**) showed that there is a presence of an **invalid image** within the dataset. This appears to be an empty folder mistakenly named like an image file. To ensure data integrity, we will proceed to **remove** this invalid image from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty folders to be removed:  ['../../data/raw/Furniture_Data/Furniture_Data/lamps/Modern/11286modern-lighting.jpg', '../../data/raw/Furniture_Data/Furniture_Data/lamps/Modern/11286modern-lighting.jpg\\\\^J']\n",
      "File resolved already.\n",
      "File resolved already.\n"
     ]
    }
   ],
   "source": [
    "empty_folder = [\n",
    "    f\"{RAW_DIR}/lamps/Modern/11286modern-lighting.jpg\",\n",
    "    rf\"{RAW_DIR}/lamps/Modern/11286modern-lighting.jpg\\^J\",\n",
    "]\n",
    "\n",
    "print (\"Empty folders to be removed: \", empty_folder)\n",
    "\n",
    "# Get the absolute path\n",
    "for i in range(len(empty_folder)):\n",
    "    empty_folder[i] = os.path.abspath(empty_folder[i])\n",
    "    if os.path.exists(empty_folder[i]):\n",
    "        os.remove(empty_folder[i])\n",
    "    else:\n",
    "        print(\"File resolved already.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inconsistent Data Format Handling\n",
    "As we conclude from the *exploratory data analysis* (EDA), there is a mismatch between the file format of `jpgD` and the other `jpg` files. Hence, to ensure that the data is consistent, we will change the file format of `jpgD` to `jpg`. Based on testing and observation, simply changing the file format from `jpgD` to `jpg` does not affect the image quality or integrity.\n",
    "\n",
    "This adjustment will help maintain consistency across the dataset and prevent any potential issues during the preprocessing and modeling stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found or has been resovled already.\n"
     ]
    }
   ],
   "source": [
    "# Original file path\n",
    "jpgd_path = f\"{RAW_DIR}/dressers/Farmhouse/30826farmhouse-coffee-tables.jpgD\"\n",
    "\n",
    "# Get the absolute path\n",
    "jpgd_path = os.path.abspath(jpgd_path)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(jpgd_path):\n",
    "    # Get the directory and file name\n",
    "    directory, filename = os.path.split(jpgd_path)\n",
    "\n",
    "    # Remove the extra characters after \".jpg\" in the filename\n",
    "    new_filename = filename.split(\".jpg\")[0] + \".jpg\"\n",
    "\n",
    "    # Create the new file path\n",
    "    new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "    # Rename the file\n",
    "    os.rename(jpgd_path, new_path)\n",
    "\n",
    "    print(f\"File renamed from '{jpgd_path}' to '{new_path}'\")\n",
    "else:\n",
    "    print(\"File not found or has been resovled already.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Labeling and Training-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage focuses on processing image filenames to extract **labels**, which will subsequently be stored as new columns within our **Pandas DataFrame**. This approach facilitates convenient access and management of images using Pandas' functionalities.\n",
    "\n",
    "Firstly, the entire dataset containing the following columns will be loaded:\n",
    "- **Path**: Relative path to the image file.\n",
    "- **Category**: The category extracted from the image filename.\n",
    "- **Style**: The style associated with the image category.\n",
    "- **Width**: Width of the image in pixels.\n",
    "- **Height**: Height of the image in pixels.\n",
    "- **MinValue**: Minimum pixel value in the image.\n",
    "- **MaxValue**: Maximum pixel value in the image.\n",
    "- **StdDev**: Standard deviation of the pixel values in the image.\n",
    "\n",
    "Next, the dataset will be divided into separate **training and testing sets** using an `80/20` split ratio. This allows us to train the model on a subset of the data while evaluating its performance on unseen data.\n",
    "\n",
    "Since our objective is to classify images and predict their styles, the split will be **stratified** based on the \"**Style**\" column. This ensures a balanced representation of different styles in both the training and testing sets, leading to a more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭───────────────────────╮\n",
      "│ Purging non-raw files │\n",
      "╰───────────────────────╯\n",
      "This is a destructive operation as files will be deleted permanently. Are you sure you want to continue? (y/n)\n",
      "\n",
      "Please wait and do not interrupt the process.\n",
      "\n",
      "Removing non-raw files...\n",
      "\n",
      ">>> Purging complete.\n",
      "\n",
      "╭──────────────╮\n",
      "│ Loading data │\n",
      "╰──────────────╯\n",
      ">>> Data is being loaded... Please wait.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75698 entries, 0 to 75697\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Path      75698 non-null  object \n",
      " 1   Category  75698 non-null  object \n",
      " 2   Style     75698 non-null  object \n",
      " 3   Width     75698 non-null  int64  \n",
      " 4   Height    75698 non-null  int64  \n",
      " 5   MinValue  75698 non-null  uint8  \n",
      " 6   MaxValue  75698 non-null  uint8  \n",
      " 7   StdDev    75698 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3), uint8(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the paths of all images within the raw directory\n",
    "image_paths = leon.get_image_paths(raw_dir)\n",
    "\n",
    "# Remove previously augmented images\n",
    "styler.boxify(\"Purging non-raw files\")\n",
    "leon.remove_nonraw_files(image_paths)\n",
    "print(\">>> Purging complete.\\n\")\n",
    "\n",
    "# Load the data\n",
    "styler.boxify(\"Loading data\")\n",
    "print(\">>> Data is being loaded... Please wait.\\n\")\n",
    "df = leon.load_data_frame(raw_dir)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>MinValue</th>\n",
       "      <th>MaxValue</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>70.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>73.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>67.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>67.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>95.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>56.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>19</td>\n",
       "      <td>255</td>\n",
       "      <td>58.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>40.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>71.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>21</td>\n",
       "      <td>255</td>\n",
       "      <td>53.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path Category        Style  \\\n",
       "0  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "1  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "2  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "3  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "4  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "5  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "6  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "7  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "8  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "9  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps  Traditional   \n",
       "\n",
       "   Width  Height  MinValue  MaxValue  StdDev  \n",
       "0    350     350         0       255  70.282  \n",
       "1    350     350         0       255  73.807  \n",
       "2    350     350         0       255  67.194  \n",
       "3    350     350         0       255  67.955  \n",
       "4    350     350         0       255  95.022  \n",
       "5    350     350         0       255  56.056  \n",
       "6    350     350        19       255  58.350  \n",
       "7    350     350         5       255  40.870  \n",
       "8    350     350         0       255  71.595  \n",
       "9    350     350        21       255  53.708  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of each style within each category in the train set:\n",
      "Category  Style        \n",
      "beds      Contemporary     1944\n",
      "          Transitional     1715\n",
      "          Traditional      1391\n",
      "          Modern            375\n",
      "          Rustic            238\n",
      "          Craftsman         184\n",
      "          Midcentury        130\n",
      "          Farmhouse          89\n",
      "          Victorian          82\n",
      "          Mediterranean      75\n",
      "          Industrial         61\n",
      "          Tropical           55\n",
      "          Beach              51\n",
      "          Southwestern       49\n",
      "          Asian              48\n",
      "          Scandinavian       33\n",
      "          Eclectic           22\n",
      "chairs    Contemporary     4172\n",
      "          Transitional     4164\n",
      "          Traditional      3748\n",
      "          Midcentury       3102\n",
      "          Modern           1484\n",
      "          Farmhouse         555\n",
      "          Industrial        495\n",
      "          Tropical          425\n",
      "          Asian             350\n",
      "          Rustic            303\n",
      "          Victorian         217\n",
      "          Scandinavian      213\n",
      "          Eclectic          201\n",
      "          Craftsman         196\n",
      "          Beach             179\n",
      "          Mediterranean     170\n",
      "          Southwestern       95\n",
      "dressers  Traditional      1697\n",
      "          Transitional     1313\n",
      "          Contemporary     1110\n",
      "          Farmhouse         512\n",
      "          Asian             392\n",
      "          Rustic            329\n",
      "          Midcentury        247\n",
      "          Modern            238\n",
      "          Industrial        194\n",
      "          Beach             154\n",
      "          Victorian         130\n",
      "          Craftsman         114\n",
      "          Mediterranean      94\n",
      "          Tropical           45\n",
      "          Eclectic           38\n",
      "          Southwestern       35\n",
      "          Scandinavian        9\n",
      "lamps     Contemporary     4567\n",
      "          Transitional     4012\n",
      "          Traditional      3738\n",
      "          Modern           1606\n",
      "          Beach            1364\n",
      "          Industrial       1319\n",
      "          Victorian         823\n",
      "          Craftsman         819\n",
      "          Asian             780\n",
      "          Midcentury        771\n",
      "          Rustic            704\n",
      "          Farmhouse         680\n",
      "          Mediterranean     680\n",
      "          Eclectic          667\n",
      "          Tropical          235\n",
      "          Southwestern      123\n",
      "          Scandinavian       93\n",
      "sofas     Transitional     1048\n",
      "          Contemporary      963\n",
      "          Traditional       555\n",
      "          Midcentury        440\n",
      "          Modern            142\n",
      "          Victorian          65\n",
      "          Tropical           28\n",
      "          Farmhouse          21\n",
      "          Southwestern       18\n",
      "          Beach              17\n",
      "          Industrial         17\n",
      "          Rustic             15\n",
      "          Scandinavian       14\n",
      "          Craftsman          13\n",
      "          Eclectic           12\n",
      "          Mediterranean       9\n",
      "          Asian               7\n",
      "tables    Traditional      3418\n",
      "          Contemporary     3028\n",
      "          Industrial       2468\n",
      "          Modern           2146\n",
      "          Farmhouse        1229\n",
      "          Midcentury       1026\n",
      "          Mediterranean     553\n",
      "          Asian             530\n",
      "          Beach             468\n",
      "          Eclectic          399\n",
      "          Craftsman         397\n",
      "          Transitional      200\n",
      "          Rustic             71\n",
      "          Victorian          46\n",
      "          Scandinavian       41\n",
      "          Southwestern       27\n",
      "          Tropical           24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print count of each style within each category in the train set\n",
    "style_counts_per_category = df.groupby(\"Category\")[\"Style\"].value_counts()\n",
    "print(\"\\nCount of each style within each category in the train set:\")\n",
    "print(style_counts_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    img_to_array,\n",
    "    load_img,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Initialize ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Random rotation up to 10 degrees\n",
    "    width_shift_range=0.1,  # Randomly shift width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
    "    shear_range=0.2,  # Shear angle in counter-clockwise direction in radians\n",
    "    zoom_range=0.2,  # Random zoom up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Don't flip images vertically\n",
    "    fill_mode=\"nearest\",  # Strategy for filling in newly created pixels\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to load images from file paths\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=(256, 256))  # Adjust target_size as needed\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Define a function to handle class imbalance within categories\n",
    "def oversample_with_augmentation(group):\n",
    "    # Count occurrences of each class\n",
    "    class_counts = group[\"Style\"].value_counts()\n",
    "    max_samples = class_counts.max()\n",
    "\n",
    "    # Initialize empty list to store augmented images and labels\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    # Apply data augmentation to minority classes\n",
    "    for style, count in class_counts.items():\n",
    "        if count < max_samples:\n",
    "            # Filter data for the minority style\n",
    "            minority_data = group[group[\"Style\"] == style]\n",
    "\n",
    "            # Load images\n",
    "            minority_images_array = load_images(minority_data[\"Path\"])\n",
    "\n",
    "            # Compute number of additional samples needed\n",
    "            num_additional_samples = max_samples - count\n",
    "\n",
    "            # Generate augmented images\n",
    "            augmented_data_generator = datagen.flow(\n",
    "                minority_images_array, batch_size=1, shuffle=False\n",
    "            )\n",
    "            for _ in range(num_additional_samples):\n",
    "                augmented_images.append(next(augmented_data_generator)[0])\n",
    "                augmented_labels.append(style)\n",
    "\n",
    "    # Create DataFrame for augmented data\n",
    "    augmented_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Path\": [\n",
    "                \"oversampled_image_{}\".format(i) for i in range(len(augmented_images))\n",
    "            ],\n",
    "            \"Style\": augmented_labels,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Concatenate the original data with the augmented data\n",
    "    augmented_group = pd.concat([group, augmented_df])\n",
    "\n",
    "    return augmented_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Assuming df contains 'ImagePath' and 'Style' columns\n",
    "grouped_df = df.groupby(\"Category\")\n",
    "\n",
    "# Apply oversampling with augmentation to each group\n",
    "oversampled_groups = [oversample_with_augmentation(group) for _, group in grouped_df]\n",
    "\n",
    "# Concatenate oversampled groups into a single DataFrame\n",
    "oversampled_df = pd.concat(oversampled_groups)\n",
    "\n",
    "# Save augmented images to disk if needed\n",
    "for i, img_array in enumerate(augmented_images):\n",
    "    img = array_to_img(img_array)\n",
    "    img.save(\"oversampled/oversampled_image_{}.jpg\".format(i))\n",
    "\n",
    "# Print count of each style within each category in the oversampled dataset\n",
    "style_counts_per_category = oversampled_df.groupby(\"Category\")[\"Style\"].value_counts()\n",
    "print(\"\\nCount of each style within each category in the oversampled dataset:\")\n",
    "print(style_counts_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of each style within each category in the train set:\n",
      "Category  Style        \n",
      "beds      Contemporary     1944\n",
      "          Transitional     1715\n",
      "          Traditional      1391\n",
      "          Modern            375\n",
      "          Rustic            238\n",
      "          Craftsman         184\n",
      "          Midcentury        130\n",
      "          Farmhouse          89\n",
      "          Victorian          82\n",
      "          Mediterranean      75\n",
      "          Industrial         61\n",
      "          Tropical           55\n",
      "          Beach              51\n",
      "          Southwestern       49\n",
      "          Asian              48\n",
      "          Scandinavian       33\n",
      "          Eclectic           22\n",
      "chairs    Contemporary     4172\n",
      "          Transitional     4164\n",
      "          Traditional      3748\n",
      "          Midcentury       3102\n",
      "          Modern           1484\n",
      "          Farmhouse         555\n",
      "          Industrial        495\n",
      "          Tropical          425\n",
      "          Asian             350\n",
      "          Rustic            303\n",
      "          Victorian         217\n",
      "          Scandinavian      213\n",
      "          Eclectic          201\n",
      "          Craftsman         196\n",
      "          Beach             179\n",
      "          Mediterranean     170\n",
      "          Southwestern       95\n",
      "dressers  Traditional      1697\n",
      "          Transitional     1313\n",
      "          Contemporary     1110\n",
      "          Farmhouse         512\n",
      "          Asian             392\n",
      "          Rustic            329\n",
      "          Midcentury        247\n",
      "          Modern            238\n",
      "          Industrial        194\n",
      "          Beach             154\n",
      "          Victorian         130\n",
      "          Craftsman         114\n",
      "          Mediterranean      94\n",
      "          Tropical           45\n",
      "          Eclectic           38\n",
      "          Southwestern       35\n",
      "          Scandinavian        9\n",
      "lamps     Contemporary     4567\n",
      "          Transitional     4012\n",
      "          Traditional      3738\n",
      "          Modern           1606\n",
      "          Beach            1364\n",
      "          Industrial       1319\n",
      "          Victorian         823\n",
      "          Craftsman         819\n",
      "          Asian             780\n",
      "          Midcentury        771\n",
      "          Rustic            704\n",
      "          Farmhouse         680\n",
      "          Mediterranean     680\n",
      "          Eclectic          667\n",
      "          Tropical          235\n",
      "          Southwestern      123\n",
      "          Scandinavian       93\n",
      "sofas     Transitional     1048\n",
      "          Contemporary      963\n",
      "          Traditional       555\n",
      "          Midcentury        440\n",
      "          Modern            142\n",
      "          Victorian          65\n",
      "          Tropical           28\n",
      "          Farmhouse          21\n",
      "          Southwestern       18\n",
      "          Beach              17\n",
      "          Industrial         17\n",
      "          Rustic             15\n",
      "          Scandinavian       14\n",
      "          Craftsman          13\n",
      "          Eclectic           12\n",
      "          Mediterranean       9\n",
      "          Asian               7\n",
      "tables    Traditional      3418\n",
      "          Contemporary     3028\n",
      "          Industrial       2468\n",
      "          Modern           2146\n",
      "          Farmhouse        1229\n",
      "          Midcentury       1026\n",
      "          Mediterranean     553\n",
      "          Asian             530\n",
      "          Beach             468\n",
      "          Eclectic          399\n",
      "          Craftsman         397\n",
      "          Transitional      200\n",
      "          Rustic             71\n",
      "          Victorian          46\n",
      "          Scandinavian       41\n",
      "          Southwestern       27\n",
      "          Tropical           24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print count of each style within each category in the train set\n",
    "style_counts_per_category = df.groupby(\"Category\")[\"Style\"].value_counts()\n",
    "print(\"\\nCount of each style within each category in the train set:\")\n",
    "print(style_counts_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭────────────────╮\n",
      "│ Splitting data │\n",
      "╰────────────────╯\n",
      ">>> Splitting data into train and test sets... Please wait.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 60559 entries, 58338 to 15795\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Path      60559 non-null  object \n",
      " 1   Category  60559 non-null  object \n",
      " 2   Style     60559 non-null  object \n",
      " 3   Width     60559 non-null  int64  \n",
      " 4   Height    60559 non-null  int64  \n",
      " 5   MinValue  60559 non-null  uint8  \n",
      " 6   MaxValue  60559 non-null  uint8  \n",
      " 7   StdDev    60559 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3), uint8(2)\n",
      "memory usage: 3.3+ MB\n",
      "lamps: 18419\n",
      "chairs: 16144\n",
      "tables: 12752\n",
      "dressers: 5278\n",
      "beds: 5251\n",
      "sofas: 2715\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "styler.boxify(\"Splitting data\")\n",
    "print(\">>> Splitting data into train and test sets... Please wait.\\n\")\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the train set\n",
    "df_train.info()\n",
    "\n",
    "# Group by the 'category' column and count the number of unique values\n",
    "category_counts = df_train[\"Category\"].value_counts()\n",
    "\n",
    "# Display the category counts\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭────────────────────────────────╮\n",
      "│ First 20 rows of the train set │\n",
      "╰────────────────────────────────╯\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>MinValue</th>\n",
       "      <th>MaxValue</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58338</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/c...</td>\n",
       "      <td>chairs</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>75.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19160</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>22.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>60.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Modern</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>96.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17652</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>255</td>\n",
       "      <td>35.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Midcentury</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>255</td>\n",
       "      <td>19.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50134</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/b...</td>\n",
       "      <td>beds</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>68.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14243</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Asian</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>49.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73203</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/c...</td>\n",
       "      <td>chairs</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>88.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Farmhouse</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>255</td>\n",
       "      <td>51.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Path Category  \\\n",
       "58338  ../../data/raw/Furniture_Data/Furniture_Data/c...   chairs   \n",
       "19160  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "1410   ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "10986  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "17652  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "4187   ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "50134  ../../data/raw/Furniture_Data/Furniture_Data/b...     beds   \n",
       "14243  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "73203  ../../data/raw/Furniture_Data/Furniture_Data/c...   chairs   \n",
       "13873  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "\n",
       "              Style  Width  Height  MinValue  MaxValue  StdDev  \n",
       "58338   Traditional    256     256         0       255  75.131  \n",
       "19160  Contemporary    256     256         6       255  22.291  \n",
       "1410    Traditional    256     256         0       255  60.138  \n",
       "10986        Modern    256     256         0       255  96.166  \n",
       "17652  Contemporary    256     256        16       255  35.015  \n",
       "4187     Midcentury    256     256        10       255  19.738  \n",
       "50134  Contemporary    256     256         0       255  68.490  \n",
       "14243         Asian    256     256         0       255  49.072  \n",
       "73203  Contemporary    256     256         0       255  88.265  \n",
       "13873     Farmhouse    256     256         8       255  51.032  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styler.boxify(\"First 20 rows of the train set\")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will resize all images to a uniform dimension. This step is crucial as it ensures that all images have the same size, which is a requirement for most machine learning models.\n",
    "\n",
    "While there's no single \"**best**\" image size for deep learning applications, we will resize our images to `256x256` pixels. This choice balances the need to capture sufficient detail in the images with computational efficiency. Additionally, research by O. Rukundo (Lund University) suggests that `256x256` pixels is a common and effective size for processing medical images, particularly **LGE-MRI** images.\n",
    "\n",
    "Although our dataset is not related to medical imaging, we can leverage this insight of its reliability to guide our decision.\n",
    "\n",
    "[Link to Research](https://www.mdpi.com/2079-9292/12/4/985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭────────────────────────────╮\n",
      "│ Resizing images to 256x256 │\n",
      "╰────────────────────────────╯\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>MinValue</th>\n",
       "      <th>MaxValue</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58338</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/c...</td>\n",
       "      <td>chairs</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>75.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19160</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>22.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>60.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Modern</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>96.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17652</th>\n",
       "      <td>../../data/raw/Furniture_Data/Furniture_Data/l...</td>\n",
       "      <td>lamps</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>255</td>\n",
       "      <td>35.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Path Category  \\\n",
       "58338  ../../data/raw/Furniture_Data/Furniture_Data/c...   chairs   \n",
       "19160  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "1410   ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "10986  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "17652  ../../data/raw/Furniture_Data/Furniture_Data/l...    lamps   \n",
       "\n",
       "              Style  Width  Height  MinValue  MaxValue  StdDev  \n",
       "58338   Traditional    256     256         0       255  75.131  \n",
       "19160  Contemporary    256     256         6       255  22.291  \n",
       "1410    Traditional    256     256         0       255  60.138  \n",
       "10986        Modern    256     256         0       255  96.166  \n",
       "17652  Contemporary    256     256        16       255  35.015  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styler.boxify(\"Resizing images to 256x256\")\n",
    "\n",
    "# Resize images to 256x256\n",
    "for img_path in df_train[\"Path\"]:\n",
    "    leon.resize_image(img_path, 256, 256)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, data augmentation is a well-established technique employed to artificially expand the size of a dataset. This is achieved by applying various transformations to the existing data points. Data augmentation proves particularly valuable when dealing with limited datasets, as it mitigates the risk of overfitting and enhances the model's ability to generalize to unseen data.\n",
    "\n",
    "While our image dataset may not be severely restricted in size, data augmentation can still provide significant benefits. We will incorporate the following transformations to augment our dataset:\n",
    "\n",
    "1. **Random Rotation**: Images will be rotated by a random angle within a predefined range.\n",
    "2. **Vertical Flip**: Images will be flipped along the vertical axis.\n",
    "3. **Random Contrast Adjustment**: The contrast of each image will be adjusted by a random factor.\n",
    "\n",
    "These aforementioned transformations are commonly utilized in image augmentation and demonstrably assist the model in learning robust features from the data [1]. It is important to note that with a dataset exceeding `65,000` images, regarding the training set, employing an excessive number of augmentation techniques would result in a computationally expensive dataset to process. Therefore, a selection of the top `3` prevalent and effective transformations has been chosen.\n",
    "\n",
    "Following this augmentation step, we will possess a dataset that is approximately **three times** larger than the original dataset (Each image will have `2` augmented versions, plus the original image). This expanded dataset will equip the model with a richer learning experience and improved generalizability.\n",
    "\n",
    "[1] [Image Data Augmentation for Computer Vision](https://viso.ai/computer-vision/image-data-augmentation-for-computer-vision/#:~:text=Popular%20Types%20and%20Methods%20of%20Data%20Augmentation,-Early%20experiments%20showing&text=Geometric%20transformations%3A%20Augmenting%20image%20data,%2Fdown%2C%20or%20noise%20injection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭───────────────────────────────────────╮\n",
      "│ Augmenting images in the training set │\n",
      "╰───────────────────────────────────────╯\n",
      "\n",
      ">>> Augmenting images in the training set... Please wait.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(img_path)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Augment images in the directory\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m leon\u001b[38;5;241m.\u001b[39maugment_image(\n\u001b[1;32m     16\u001b[0m         image_path\u001b[38;5;241m=\u001b[39mimg_path, output_dir\u001b[38;5;241m=\u001b[39mdirectory, df_train\u001b[38;5;241m=\u001b[39mdf_train\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the filtered DataFrame\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/workspace/MLGroup/notebooks/data_analysis/../../scripts/leon.py:289\u001b[0m, in \u001b[0;36mLeon.augment_image\u001b[0;34m(self, image_path, output_dir, df_train, num_images, rotation, contrast)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# Add the augmented image to the dataframe\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    277\u001b[0m         {\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m\"\u001b[39m: [output_path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m     )\n\u001b[0;32m--> 289\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_train, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_train\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "styler.boxify(\"Augmenting images in the training set\")\n",
    "\n",
    "print(\"\\n>>> Augmenting images in the training set... Please wait.\\n\")\n",
    "\n",
    "# Augment images in the training set\n",
    "for img_path in df_train[\"Path\"]:\n",
    "    # Check if img_path starts with \"aug_\"\n",
    "    if os.path.basename(img_path).strip().startswith(\"aug_\"):\n",
    "        continue\n",
    "\n",
    "    # Extract directory name\n",
    "    directory = os.path.dirname(img_path)\n",
    "\n",
    "    # Augment images in the directory\n",
    "    df_train = leon.augment_image(\n",
    "        image_path=img_path, output_dir=directory, df_train=df_train\n",
    "    )\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pixel Normalization\n",
    "\n",
    "Normalization is a critical stage in preprocessing image data for deep learning applications. It ensures all pixel values fall within a consistent range, typically between `0` and `1`. This seemingly simple step offers several advantages:\n",
    "\n",
    "- **Faster Convergence**: By reducing the overall value range, normalization accelerates the convergence of the optimization algorithm used to train the model.\n",
    "- **Improved Stability**: Normalization creates a more stable training process, mitigating issues like vanishing and exploding gradients:\n",
    "\n",
    "    - *Vanishing Gradients*: In deep learning, vanishing gradients occur when the gradients (slopes) of the loss function become very small as they propagate backward through the layers of a deep neural network. This can cause the model to learn very slowly or not at all.\n",
    "    \n",
    "    - *Exploding Gradients*: Conversely, exploding gradients happen when gradients become excessively large, causing the model to diverge (lose stability) during training.\n",
    "- **Boosted Performance**: Consistent input data, achieved through normalization, often leads to better model performance and generalization on unseen data.\n",
    "\n",
    "It's important to acknowledge that the normalization range is not restricted to `[0, 1]`. Other techniques, such as **Z-score normalization**, may be appropriate depending on the specific model and data characteristics. However, due to its simplicity and effectiveness, `[0, 1]` normalization remains a popular choice for preprocessing pipelines.\n",
    "\n",
    "### Note: The Normalization Will Not Be Performed At This Stage\n",
    "\n",
    "While the normalization process itself is successful, it is not recommended to save the **normalized images** to disk afterwards. This is due to a data type mismatch. The original images are stored in an unsigned 8-bit integer format (**uint8**), whereas the **normalized images** are in a single-precision floating-point format (**float32**). This conversion can lead to a loss of color information and a reduction in image sharpness.\n",
    "\n",
    "Consequently, to avoid this issue, the normalization process will be performed during the **model training** phase. During training, the normalization will be applied dynamically to the input data, ensuring compatibility with the model's input requirements without compromising image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, data preprocessing is a crucial step in the machine learning pipeline. By applying the techniques outlined in this notebook, we have prepared our dataset for model training. The data is now **clean**, **labeled**, **split into training and testing sets**, **resized**, **augmented**, and **normalized**.\n",
    "\n",
    "These preprocessing steps are essential for ensuring that the model can learn effectively from the data and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display info of the training set\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the filtered DataFrame\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train set to CSV\n",
    "try:\n",
    "    styler.boxify(\"Writing train set to CSV\")\n",
    "    df_train.to_csv(\"../../data/processed/train.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print (\">>> Data saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
